#  Visual Embedding Analysis for X-rays of Cats & Dogs Dataset
This project explores how modern foundation vision models represent medical X-ray images.  
We extract embeddings using **DINOv2**, combine them with **SAM2 segmentation**, and compare how well the representations cluster cats vs. dogs using **UMAP**, **t-SNE**, and quantitative metrics.

This notebook demonstrates:
- Clean preprocessing for medical X-rays (CLAHE, resizing, RGB conversion)  
- High-quality embeddings using **DINOv2 (ViT-S/14)**  
- Correct SAM2 workflow (segmentation â†’ masked image â†’ DINOv2 embedding)  
- Dimensionality reduction (UMAP + t-SNE)  
- Clustering quality evaluation (Silhouette Score, Daviesâ€“Bouldin Index)  
- Static and interactive visualizations  
- Full reproducibility with structured outputs


## ğŸ“ Project Structure

```
AI4See-Assignment/
â”‚
â”œâ”€â”€ notebook.ipynb
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ processed_images/
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ embeddings/
â”‚ â”œâ”€â”€ plots/
â”‚ â””â”€â”€ interactive/
â”‚
â””â”€â”€ test-dataset/
â”œâ”€â”€ cat1/
â””â”€â”€ dog1/
```


## ğŸš€ Methodology

### **1. Preprocessing**
- Load X-ray images in grayscale  
- Apply **CLAHE** (improves X-ray contrast)  
- Resize â†’ Convert to RGB  
- Normalize to ImageNet statistics (for DINOv2)

### **2. Embedding Extraction**
#### **A. DINOv2 (Full Image)**
- Use `dinov2_vits14` from Facebook Research
- Extract 384-dimensional embeddings  
- Very fast on GPU

#### **B. SAM2 + DINOv2 (Segmented Version)**
- Use SAM2 to segment the primary anatomical region  
- Apply DINOv2 only on masked region  
- Produces embeddings with reduced background noise

### **3. Dimensionality Reduction**
- **UMAP** (cosine metric)  
- **t-SNE** (perplexity = 30, cosine metric)  
- Produces 2-D visual clusters

### **4. Clustering Metrics**
We compute:

| Method | Silhouette â†‘ | Davies-Bouldin â†“ |
|--------|--------------|------------------|
| DINOv2 + UMAP | 0.0414 | 7.6403 |
| DINOv2 + t-SNE | 0.0693 | 5.0226 |
| SAMâ†’DINOv2 + UMAP | 0.0058 | 17.3990 |
| SAMâ†’DINOv2 + t-SNE | 0.0109 | 13.5544 |


## ğŸ“Š Key Insights

- **DINOv2 full-image embeddings outperform segmented SAM2 versions**  
  â†’ SAM segmentation over-cropped anatomical details, weakening class separation.

- **t-SNE consistently produced slightly better separation than UMAP.**

- **Dataset is extremely challenging**  
  â†’ Anatomical X-rays of cats and dogs look extremely similar.  
  â†’ Even state-of-the-art models show low inter-class variance.

- **Pipeline is fully reproducible and works on CPU/GPU**, with GPU providing ~10Ã— speedup.


## ğŸ“ How to Run
1. Clone the repository  
2. Install dependencies:
```
pip install -r requirements.txt
```


3. Open the notebook:
```
jupyter notebook notebook.ipynb
```

4. Run all cells â€” outputs appear under `outputs/`.


## ğŸ¥ Demo
A short demonstration video is included showing:
- Notebook execution  
- Intermediate visual outputs  
- Final cluster comparison  

## ğŸ“Œ Author
**Mohammed Tawfiq**  
AI/ML Engineer â€” Computer Vision & GenAI  
